---
title: "Practical Machine Learning Course Project"
author: "Dhruvang Jhaveri"
date: "April 26, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###**Introduction**  
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. We have data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website [here](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).  
In this project, our goal is to predict the manner in which they did the exercise. The outcome of the prediction is the "classe" variable having 5 factors- "A","B","C","D"&"E", that denote the quality of the excersice being performed. 

###**Prediction Study Design**  
Loading required packages, setting seed, and loading training & testing data
```{r, message=FALSE}
library(caret)
library(dplyr)
set.seed(55)
data <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
```
The "testdata" will be used to make prediction by our final algorithm.
The "data" which is our training data is partitioned into 3 different data sets as follows-
```{r}
inTrain <- createDataPartition(y=data$classe, p=0.8, list = F)
train_test <- data[inTrain,]
validation <- data[-inTrain,]
inTrain <- createDataPartition(y=train_test$classe, p=0.8, list = F)
training <- train_test[inTrain,]
testing <- train_test[-inTrain,]
```
Partioning accomplishes 3 objectives  


- training set used to train different machine learning algorithms
- testing set used to test different algorithms to select the best one and then calculate the in-sample error rate. 
- validation set used to test our final algorithm and calculate out of sample error rate. 


##**Cleaning Data**  
Now, we start working with our training dataset.   
On exploring our dataset we find out that out of the 12,562 rows, 67 variables have 12,291 NAs and another 33 variables have 12,291 missing values in the form of "". These variables obviously cannot be used for model building and thus need to be removed from our training dataset. Also the 1st varible "X" indicating the row number is removed. 
```{r}
x <- sapply(training, function(x) sum(is.na(x)))
x <- x[x>0]
x <- match(names(x),names(training))
training <- dplyr::select(training, -x)
x <- sapply(training, function(x) sum(x%in%""))
x <- x[x>0]
x <- match(names(x),names(training))
training <- dplyr::select(training, -x)
training <- training[,-1]
```


